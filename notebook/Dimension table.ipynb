{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Dimension table - Data Cleaning\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "##### Purpose of the noode book:\r\n",
        "1. Clean duplicate, null values from dimension tables\r\n",
        "2. Write to gold layer data storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Set the folder paths so that it can be used later\r\n",
        "silver_folder_path = 'abfss://ws-container@bogomarketingdl.dfs.core.windows.net/silver'\r\n",
        "gold_folder_path = 'abfss://ws-container@bogomarketingdl.dfs.core.windows.net/gold'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "sparksql"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "CREATE DATABASE IF NOT EXISTS gold_reward_program_spark\r\n",
        "LOCATION 'abfss://ws-container@bogomarketingdl.dfs.core.windows.net/gold';"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "customer_profile = spark.read.parquet(f\"{silver_folder_path}/customer_profile\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "customer_profile.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql.functions import col,isnan, when, count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "customer_profile.filter(customer_profile.gender.isNull()).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "customer_profile = customer_profile.na.fill(\"Unknown\", subset=['gender'])\r\n",
        "customer_profile = customer_profile.na.fill(0, subset=['income'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "customer_profile.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in ['gender', 'age', 'income']]\r\n",
        "   ).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "sparksql"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "Drop table if exists gold_reward_program_spark.customer_profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "customer_profile.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"gold_reward_program_spark.customer_profile\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "offer_type = spark.read.parquet(f\"{silver_folder_path}/offer_type\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "offer_type.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql import functions as F\r\n",
        "\r\n",
        "# List of unique channels across all columns\r\n",
        "channels = ['web', 'email', 'mobile', 'social']\r\n",
        "\r\n",
        "# Iterate over each channel and create a dummy column for it\r\n",
        "for channel in channels:\r\n",
        "    # Check if the channel appears in any of the four channel columns\r\n",
        "    offer_type = offer_type.withColumn(f'channel_{channel}', \r\n",
        "                       F.when(\r\n",
        "                           (F.col('channel_1') == channel) |\r\n",
        "                           (F.col('channel_2') == channel) |\r\n",
        "                           (F.col('channel_3') == channel) |\r\n",
        "                           (F.col('channel_4') == channel), 1\r\n",
        "                       ).otherwise(0))\r\n",
        "\r\n",
        "# Drop original channel columns if no longer needed\r\n",
        "offer_type = offer_type.drop('channel_1', 'channel_2', 'channel_3', 'channel_4')\r\n",
        "\r\n",
        "# Show the resulting DataFrame\r\n",
        "offer_type.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "offer_type.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"gold_reward_program_spark.offer_type\")"
      ]
    }
  ]
}